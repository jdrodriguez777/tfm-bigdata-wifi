{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In \\[1\\]:\n",
    "\n",
    "    import apache_beam as beam\n",
    "    from apache_beam.options import pipeline_options\n",
    "    from apache_beam.options.pipeline_options import GoogleCloudOptions\n",
    "    from apache_beam.runners import DataflowRunner\n",
    "    import google.auth\n",
    "    import json\n",
    "    import re\n",
    "\n",
    "In \\[2\\]:\n",
    "\n",
    "    # Configuración de las opciones del pipeline Apache Beam.\n",
    "    options = pipeline_options.PipelineOptions(flags=[])\n",
    "\n",
    "    # Establece el proyecto como el proyecto por defecto en su actual entorno de Google Cloud.\n",
    "    _, options.view_as(GoogleCloudOptions).project = google.auth.default()\n",
    "\n",
    "    # Región de Google Cloud en la cual va a correr Dataflow.\n",
    "    options.view_as(GoogleCloudOptions).region = 'us-east1'\n",
    "\n",
    "    # Debido a que este notebook viene con una versión construida localmente del SDK\n",
    "    # de Beam Python, se necesita establecer la opción sdk_location para el Dataflow Runner.\n",
    "    options.view_as(pipeline_options.SetupOptions).sdk_location = (\n",
    "        '/root/apache-beam-custom/packages/beam/sdks/python/dist/apache-beam-%s0.tar.gz' % \n",
    "        beam.version.__version__)\n",
    "\n",
    "In \\[3\\]:\n",
    "\n",
    "    # Carpeta de trabajo en el bucket jrodriguez-test de Google Cloud Storage.\n",
    "    dataflow_gcs_location = 'gs://jrodriguez-test/dataflow'\n",
    "\n",
    "In \\[4\\]:\n",
    "\n",
    "    # Ubicación de carpetas temporales de Dataflow.\n",
    "    options.view_as(GoogleCloudOptions).staging_location = '%s/staging' % dataflow_gcs_location\n",
    "    options.view_as(GoogleCloudOptions).temp_location = '%s/temp' % dataflow_gcs_location\n",
    "\n",
    "In \\[5\\]:\n",
    "\n",
    "    # Clases que heredan de PTransform, que se usan en un pipeline más adelante junto\n",
    "    # con otras Ptransform.\n",
    "\n",
    "    # Lee archivo el archivo json y lo transforma en PCollection\n",
    "    class ReadData(beam.PTransform):\n",
    "        \n",
    "        #Recibe la ruta\n",
    "        def __init__(self, file_pattern):\n",
    "            self._file_pattern = file_pattern\n",
    "        \n",
    "        # Ejecución. Recibe PCollection.\n",
    "        def expand(self, pcoll):\n",
    "            # Inicio de pipeline de ejecución.\n",
    "            return (pcoll.pipeline\n",
    "                    # Lectura del archivo plano hacia Beam.\n",
    "                    | beam.io.ReadFromText(self._file_pattern)\n",
    "                    # Cargar las filas como json y retorna PCollection.\n",
    "                    | beam.Map(json.loads))\n",
    "\n",
    "    # Filtra las filas que tienen valor rssi menor al valor que\n",
    "    # recibe como parámetro (value). Continúa la ejecución con\n",
    "    # las que tienen valor rssi mayor o igual.\n",
    "    class FilterRssi(beam.PTransform):\n",
    "        \n",
    "        def __init__(self, value):\n",
    "            self.value = value\n",
    "        # Recibe la anterior PCollection en el pipeline\n",
    "        def expand(self, pcoll):\n",
    "            return (pcoll\n",
    "                    | beam.Filter(lambda row: row['rssi'] >= self.value))\n",
    "        \n",
    "    # Deja sólo los id client y luego selecciona los distintos ids.\n",
    "    class Distinct(beam.PTransform):\n",
    "\n",
    "        def expand(self, pcoll):\n",
    "            return (pcoll\n",
    "                    | beam.Map(lambda x: x.get('client'))\n",
    "                    | beam.transforms.util.Distinct())\n",
    "        \n",
    "    # Transforma cada fila del PCollection que recibe a la forma de\n",
    "    # tupla (client, [lista de tiempos de cada visita])\n",
    "    class Visits(beam.PTransform):\n",
    "        \n",
    "        # Recibe el umbral de visita\n",
    "        def __init__(self, rssiVisit):\n",
    "            self.rssiVisit = rssiVisit\n",
    "\n",
    "        # Función aplicada a cada fila del PCollection como map\n",
    "        # (en la función expand), que retorna la lista de tiempos\n",
    "        # de cada visita de client.\n",
    "        # Recibe una lista de tuplas de un client:\n",
    "        # [(rssi, date), (rssi, date), ...]\n",
    "        def getVisits(self, dataList):\n",
    "            \n",
    "            dataList = list(dataList)\n",
    "            # Se ordena la lista por date\n",
    "            dataList.sort(key=lambda rssi_date: rssi_date[1])\n",
    "        \n",
    "            # Lista de listas de visitas\n",
    "            visitsList = []\n",
    "            # Lista de tuplas\n",
    "            visit = []\n",
    "            # Se itera la lista de tuplas.\n",
    "            # Para una iteración se compara con date de la anterior,\n",
    "            # para eso se usa previousDate. Se inicia con el primer valor.\n",
    "            previousDate = dataList[0][1]\n",
    "            for rssi_date in dataList:\n",
    "                # Si la diferencia del tiempo anterior con el actual\n",
    "                # es menor de media hora. En la primera iteración es 0,\n",
    "                # por tanto ingresa al if.\n",
    "                if rssi_date[1]-previousDate < 1800000:\n",
    "                    # Carga un registro de la visita como tupla (rssi, date)\n",
    "                    visit.append(rssi_date)\n",
    "                # Si es mayor o igual, ese registro hace parte de la siguiente\n",
    "                # visita. En la lista de listas se agrega la visita anterior\n",
    "                # y se empieza una nueva con el primer registro.\n",
    "                else:\n",
    "                    visitsList.append(visit)\n",
    "                    visit = [rssi_date]\n",
    "                previousDate = rssi_date[1]\n",
    "            # Agrega la última visita.\n",
    "            visitsList.append(visit)\n",
    "            \n",
    "            # Hace falta que que haya mínimo una medición mayor al umbral de visita\n",
    "            # y que el tiempo entre esa medición y la última sea menor que 5 minutos,\n",
    "            # para que se considere una visita como tal.\n",
    "            \n",
    "            # Lista de los tiempos de visitas reales.\n",
    "            realVisits = []\n",
    "            # Se itera la lista de listas anterior\n",
    "            for visit in visitsList:\n",
    "                visitSize = len(visit)\n",
    "                # Se itera la lista de tuplas de registros correspondientes a una\n",
    "                # visita, hasta el penúltimo registro, y se confirma que pase\n",
    "                # el umbral de visita, ...\n",
    "                for i in range(visitSize-1):\n",
    "                    if visit[i][0] >= self.rssiVisit:\n",
    "                        # ... de ser así toma el tiempo de diferencia entre dicha\n",
    "                        # medida y la última, ...\n",
    "                        visitTime = visit[visitSize-1][1] - visit[i][1]\n",
    "                        # ... si es mayor que 5 minutos, agrega el tiempo.\n",
    "                        if visitTime >= 300000:\n",
    "                            realVisits.append(visitTime)\n",
    "                        # Como ya encontró la medición requerida, quiebra el for.\n",
    "                        break\n",
    "\n",
    "            return realVisits\n",
    "\n",
    "        # Recibe PCollection anterior en el pipeline y aplica transformación las filas.\n",
    "        def expand(self, pcoll):\n",
    "            return (pcoll\n",
    "                    | beam.MapTuple(lambda client, dataList: (client, self.getVisits(dataList))))\n",
    "        \n",
    "    # Calcula el tiempo promedio de las visitas de cada client.\n",
    "    class VisitorsTimeAvg(beam.PTransform):\n",
    "\n",
    "        # Calcula el promedio de una lista de enteros, y el valor lo convierte a minutos.\n",
    "        def mean(self, dataList):\n",
    "            total = 0\n",
    "            for data in dataList:\n",
    "                total += data\n",
    "            return int(total/(60000*len(dataList)))\n",
    "        \n",
    "        def expand(self, pcoll):\n",
    "            return (pcoll\n",
    "                | beam.MapTuple(lambda client, dataList: (client, self.mean(dataList))))\n",
    "\n",
    "    # Recibe un PCollection con filas de la forma (client, número de visitas) y suma las visitas.\n",
    "    class VisitsSum(beam.PTransform):\n",
    "\n",
    "        def expand(self, pcoll):\n",
    "            return (pcoll\n",
    "                | beam.Map(lambda row: row[1])\n",
    "                | beam.CombineGlobally(sum))\n",
    "\n",
    "In \\[6\\]:\n",
    "\n",
    "    # Creación de pipeline p con un DataflowRunner por defecto, y recibe las opciones\n",
    "    # de configuración inicializadas al principio del notebook.\n",
    "    p = beam.Pipeline(DataflowRunner(), options=options)\n",
    "\n",
    "In \\[7\\]:\n",
    "\n",
    "    # ----- PIPELINE -----\n",
    "\n",
    "    # Lee el archivo json y filtra para quedarse con las filas que tengan rssi mayor a 10 dBm.\n",
    "    transeuntes = (p | 'lectura' >> ReadData('gs://jrodriguez-test/FuzzyData.txt')\n",
    "                     | 'filtroUmbralTranseuntes' >> FilterRssi(10))\n",
    "\n",
    "    # Toma los id client distintos del PCollection transeuntes\n",
    "    transeuntesMac = transeuntes | 'transeuntesDistintos' >> Distinct()\n",
    "\n",
    "    # Cuenta el número de ids únicas de la salida anterior transeuntes.\n",
    "    totalTranseuntes = transeuntesMac | 'conteoTranseuntes' >> beam.combiners.Count.Globally()\n",
    "\n",
    "    # A partir de este punto ya registros de mediciones con umbral de transeúntes, ahora\n",
    "    # queremos encontrar los visitantes.\n",
    "    visitantesTiempoVisitas = (transeuntes\n",
    "        # Primer filtro (de dos) para poder pertenecer a una visita.\n",
    "        | 'filtroUmbralVisitantes' >> FilterRssi(15)\n",
    "        # Transforma las filas del PCollection recibido a tuplas de la forma ( client, (rssi, date) )\n",
    "        | 'seleccionVariables' >> beam.Map(lambda x: (x.get('client'),(x.get('rssi'), x.get('date'))))\n",
    "        # Agrupa por id client único y por cada uno obtiene una lista de tuplas. Cada fila queda de la\n",
    "        # forma ( client, [lista de tuplas (rssi, date)] )\n",
    "        | 'agruparMac' >> beam.transforms.core.GroupByKey()\n",
    "        # Calcula las visitas y convierte cada fila a la forma ( client, [lista de tiempos visitas])\n",
    "        | 'obtenerVisitas' >> Visits(20)\n",
    "        # Sólo continúan los que quedaron con elementos en la lista.\n",
    "        | 'filtroVisitantes' >> beam.Filter(lambda row : len(row[1]) > 0))\n",
    "\n",
    "    # Recibe la PCollection visitantesTiempoVisitas y calcula el tiempo promedio. Cada fila queda\n",
    "    # transformada de la forma: (client, tiempo_promedio_visita)\n",
    "    visitantesTiempoProm = (visitantesTiempoVisitas\n",
    "        | 'promedio' >> VisitorsTimeAvg())\n",
    "\n",
    "    # Recibe también la PCollection visitantesTiempoVisitas y hace el conteo de visitantes.\n",
    "    totalVisitantes = (visitantesTiempoVisitas\n",
    "        | 'conteoVisitantes' >> beam.combiners.Count.Globally())\n",
    "\n",
    "    # Recibe también la PCollection visitantesTiempoVisitas y calcula el número de visitas de cada\n",
    "    # client, mediante la longitud de la lista de tiempos. Cada fila queda de la forma:\n",
    "    # (client, número_visitas)\n",
    "    visitasCliente = (visitantesTiempoVisitas\n",
    "        | 'conteoVisitas' >> beam.MapTuple(lambda client, dataList: (client, len(dataList))))\n",
    "\n",
    "    # Suma todos los valores de la PCollection visitasCliente para obtener el total de visitas.\n",
    "    totalVisitas = visitasCliente | 'sumaVisitas' >> VisitsSum()\n",
    "\n",
    "In \\[8\\]:\n",
    "\n",
    "    # Directorio para almacenar los archivos de salida del trabajo.\n",
    "    output_gcs_location = '%s/output' % dataflow_gcs_location\n",
    "\n",
    "    # Se incorporan las salidas del pipeline para escribir en Storage\n",
    "    # en formato csv, mediante PTransforms de entrada/salida.\n",
    "\n",
    "    (transeuntesMac\n",
    "        | 'Write transeuntes to GCS' >> beam.io.WriteToText(\n",
    "            # Nombre del archivo con toda la ruta.\n",
    "            output_gcs_location + '/transeuntes',\n",
    "            file_name_suffix='.csv'))\n",
    "\n",
    "    (totalTranseuntes\n",
    "        | 'Write totalTranseuntes to GCS' >> beam.io.WriteToText(\n",
    "            output_gcs_location + '/totalTranseuntes',\n",
    "            file_name_suffix='.csv'))\n",
    "\n",
    "    (visitantesTiempoVisitas\n",
    "        | 'Write visitantesTiempoVisita to GCS' >> beam.io.WriteToText(\n",
    "            output_gcs_location + '/visitantesTiempoVisitas',\n",
    "            file_name_suffix='.csv',\n",
    "            header='mac,tiempos'))\n",
    "        \n",
    "    (visitantesTiempoProm\n",
    "        | beam.Map(lambda x: re.sub(\"\\(|\\)|\\'\", \"\", str(x)))\n",
    "        | 'Write visitantesTiempoProm to GCS' >> beam.io.WriteToText(\n",
    "            output_gcs_location + '/visitantesTiempoProm',\n",
    "            file_name_suffix='.csv',\n",
    "            header='mac,tiempoProm'))\n",
    "\n",
    "    (totalVisitantes\n",
    "        | 'Write totalVisitantes to GCS' >> beam.io.WriteToText(\n",
    "            output_gcs_location + '/totalVisitantes',\n",
    "            file_name_suffix='.csv',\n",
    "            header='totalVisitantes'))\n",
    "\n",
    "    (visitasCliente\n",
    "        | beam.Map(lambda x: re.sub(\"\\(|\\)|\\'\", \"\", str(x)))\n",
    "        | 'Write visitasCliente to GCS' >> beam.io.WriteToText(\n",
    "            output_gcs_location + '/visitasCliente',\n",
    "            file_name_suffix='.csv',\n",
    "            header='mac,visitas'))\n",
    "\n",
    "    (totalVisitas\n",
    "        | 'Write totalVisitas to GCS' >> beam.io.WriteToText(\n",
    "            output_gcs_location + '/totalVisitas',\n",
    "            file_name_suffix='.csv',\n",
    "            header='totalVisitas'))\n",
    "\n",
    "Out\\[8\\]:\n",
    "\n",
    "    <PCollection[[8]: Write totalVisitas to GCS/Write/WriteImpl/FinalizeWrite.None] at 0x7f521d84d210>\n",
    "\n",
    "### Running the pipeline<a href=\"#Running-the-pipeline\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "Now we are ready to run the pipeline on Dataflow. `p.run()` will run the\n",
    "pipeline and return a pipeline result object.\n",
    "\n",
    "In \\[9\\]:\n",
    "\n",
    "    # Corre pipeline y retorna el resultado.\n",
    "    pipeline_result = p.run()\n",
    "\n",
    "    WARNING:root:Make sure that locally built Python SDK docker image has Python 3.7 interpreter.\n",
    "\n",
    "Let's wait for the job to finish. The following call will block until\n",
    "the job is finished. It will take a few minutes.\n",
    "\n",
    "In \\[10\\]:\n",
    "\n",
    "    # El siguiente llamado espera hasta que el trabajo concluya. Toma unos minutos.\n",
    "    pipeline_result.wait_until_finish()\n",
    "\n",
    "Out\\[10\\]:\n",
    "\n",
    "    'DONE'\n",
    "\n",
    "In \\[11\\]:\n",
    "\n",
    "    # Cuando el trabajo terminó podemos mirar muestras de los resultados, mediante el comando gsutil y head\n",
    "    !gsutil ls {output_gcs_location}\n",
    "\n",
    "    gs://jrodriguez-test/dataflow/output/totalTranseuntes-00000-of-00001.csv\n",
    "    gs://jrodriguez-test/dataflow/output/totalVisitantes-00000-of-00001.csv\n",
    "    gs://jrodriguez-test/dataflow/output/totalVisitas-00000-of-00001.csv\n",
    "    gs://jrodriguez-test/dataflow/output/transeuntes-00000-of-00003.csv\n",
    "    gs://jrodriguez-test/dataflow/output/transeuntes-00001-of-00003.csv\n",
    "    gs://jrodriguez-test/dataflow/output/transeuntes-00002-of-00003.csv\n",
    "    gs://jrodriguez-test/dataflow/output/visitantesTiempoProm-00000-of-00003.csv\n",
    "    gs://jrodriguez-test/dataflow/output/visitantesTiempoProm-00001-of-00003.csv\n",
    "    gs://jrodriguez-test/dataflow/output/visitantesTiempoProm-00002-of-00003.csv\n",
    "    gs://jrodriguez-test/dataflow/output/visitantesTiempoVisitas-00000-of-00003.csv\n",
    "    gs://jrodriguez-test/dataflow/output/visitantesTiempoVisitas-00001-of-00003.csv\n",
    "    gs://jrodriguez-test/dataflow/output/visitantesTiempoVisitas-00002-of-00003.csv\n",
    "    gs://jrodriguez-test/dataflow/output/visitasCliente-00000-of-00003.csv\n",
    "    gs://jrodriguez-test/dataflow/output/visitasCliente-00001-of-00003.csv\n",
    "    gs://jrodriguez-test/dataflow/output/visitasCliente-00002-of-00003.csv\n",
    "\n",
    "In \\[12\\]:\n",
    "\n",
    "    !gsutil cat {output_gcs_location}/transeuntes* | head -10\n",
    "\n",
    "    80:4c:55:9b:eb:3a\n",
    "    34:02:fd:53:d9:02\n",
    "    00:99:4a:c4:5e:2b\n",
    "    c8:c1:7f:3f:69:a3\n",
    "    00:99:4a:9f:29:bf\n",
    "    c8:c1:7f:b1:80:a6\n",
    "    44:e3:73:2e:3f:43\n",
    "    34:02:fd:f6:7a:c7\n",
    "    c8:c1:7f:32:56:8c\n",
    "    cc:0e:eb:3b:34:a6\n",
    "\n",
    "In \\[13\\]:\n",
    "\n",
    "    !gsutil cat {output_gcs_location}/totalTranseuntes* | head -10\n",
    "\n",
    "    14704\n",
    "\n",
    "In \\[14\\]:\n",
    "\n",
    "    !gsutil cat {output_gcs_location}/totalVisitantes* | head -10\n",
    "\n",
    "    totalVisitantes\n",
    "    1507\n",
    "\n",
    "In \\[15\\]:\n",
    "\n",
    "    !gsutil cat {output_gcs_location}/visitantesTiempoProm* | head -10\n",
    "\n",
    "    mac,tiempoProm\n",
    "    64:25:e6:42:71:00, 6\n",
    "    34:02:fd:63:ae:d7, 23\n",
    "    68:4c:32:20:11:c4, 84\n",
    "    68:cb:dc:95:32:57, 83\n",
    "    c8:ba:ab:9e:c5:e5, 15\n",
    "    d8:a9:20:d9:85:c8, 16\n",
    "    b4:b2:f1:6d:6e:e5, 42\n",
    "    18:62:4e:db:e7:29, 8\n",
    "    7c:04:7d:3b:97:6e, 12\n",
    "\n",
    "In \\[16\\]:\n",
    "\n",
    "    !gsutil cat {output_gcs_location}/visitantesTiempoVisitas* | head -10\n",
    "\n",
    "    mac,tiempos\n",
    "    ('e4:a0:08:df:57:ee', [6439000, 7704000])\n",
    "    ('84:39:de:a3:92:e7', [86409000])\n",
    "    ('bc:be:40:72:fb:d1', [4049000])\n",
    "    ('a8:f4:9b:f9:0a:34', [892000])\n",
    "    ('34:5f:58:4f:ab:c1', [3648000])\n",
    "    ('10:8c:79:06:9f:72', [621000, 391000])\n",
    "    ('cc:32:de:b1:74:45', [313000])\n",
    "    ('f4:aa:d4:5b:9a:4f', [1727000])\n",
    "    ('14:7e:f7:95:85:f1', [2339000])\n",
    "\n",
    "In \\[17\\]:\n",
    "\n",
    "    !gsutil cat {output_gcs_location}/visitasCliente* | head -10\n",
    "\n",
    "    mac,visitas\n",
    "    64:25:e6:42:71:00, 1\n",
    "    34:02:fd:63:ae:d7, 1\n",
    "    68:4c:32:20:11:c4, 1\n",
    "    68:cb:dc:95:32:57, 1\n",
    "    c8:ba:ab:9e:c5:e5, 1\n",
    "    d8:a9:20:d9:85:c8, 1\n",
    "    b4:b2:f1:6d:6e:e5, 1\n",
    "    18:62:4e:db:e7:29, 1\n",
    "    7c:04:7d:3b:97:6e, 1\n",
    "\n",
    "In \\[18\\]:\n",
    "\n",
    "    !gsutil cat {output_gcs_location}/totalVisitas* | head -10\n",
    "\n",
    "    totalVisitas\n",
    "    1653"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
