{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wifi_dataflow.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LldRKlWDIfDK"
      },
      "source": [
        "import apache_beam as beam\n",
        "from apache_beam.options import pipeline_options\n",
        "from apache_beam.options.pipeline_options import GoogleCloudOptions\n",
        "from apache_beam.runners import DataflowRunner\n",
        "import google.auth\n",
        "import json\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YtB9kgIIo7x"
      },
      "source": [
        "# Configuración de las opciones del pipeline Apache Beam.\n",
        "options = pipeline_options.PipelineOptions(flags=[])\n",
        "\n",
        "# Establece el proyecto como el proyecto por defecto en su actual entorno de Google Cloud.\n",
        "_, options.view_as(GoogleCloudOptions).project = google.auth.default()\n",
        "\n",
        "# Región de Google Cloud en la cual va a correr Dataflow.\n",
        "options.view_as(GoogleCloudOptions).region = 'us-east1'\n",
        "\n",
        "# Debido a que este notebook viene con una versión construida localmente del SDK\n",
        "# de Beam Python, se necesita establecer la opción sdk_location para el Dataflow Runner.\n",
        "options.view_as(pipeline_options.SetupOptions).sdk_location = (\n",
        "    '/root/apache-beam-custom/packages/beam/sdks/python/dist/apache-beam-%s0.tar.gz' % \n",
        "    beam.version.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CsEmBaFIrv_"
      },
      "source": [
        "# Carpeta de trabajo en el bucket jrodriguez-test de Google Cloud Storage.\n",
        "dataflow_gcs_location = 'gs://jrodriguez-test/dataflow'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XZuNmxRIvm_"
      },
      "source": [
        "# Ubicación de carpetas temporales de Dataflow.\n",
        "options.view_as(GoogleCloudOptions).staging_location = '%s/staging' % dataflow_gcs_location\n",
        "options.view_as(GoogleCloudOptions).temp_location = '%s/temp' % dataflow_gcs_location"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw-0AbrQI0t-"
      },
      "source": [
        "# Clases que heredan de PTransform, que se usan en un pipeline más adelante junto\n",
        "# con otras Ptransform.\n",
        "\n",
        "# Lee archivo el archivo json y lo transforma en PCollection\n",
        "class ReadData(beam.PTransform):\n",
        "    \n",
        "    #Recibe la ruta\n",
        "    def __init__(self, file_pattern):\n",
        "        self._file_pattern = file_pattern\n",
        "    \n",
        "    # Ejecución. Recibe PCollection.\n",
        "    def expand(self, pcoll):\n",
        "        # Inicio de pipeline de ejecución.\n",
        "        return (pcoll.pipeline\n",
        "                # Lectura del archivo plano hacia Beam.\n",
        "                | beam.io.ReadFromText(self._file_pattern)\n",
        "                # Cargar las filas como json y retorna PCollection.\n",
        "                | beam.Map(json.loads))\n",
        "\n",
        "# Filtra las filas que tienen valor rssi menor al valor que\n",
        "# recibe como parámetro (value). Continúa la ejecución con\n",
        "# las que tienen valor rssi mayor o igual.\n",
        "class FilterRssi(beam.PTransform):\n",
        "    \n",
        "    def __init__(self, value):\n",
        "        self.value = value\n",
        "    # Recibe la anterior PCollection en el pipeline\n",
        "    def expand(self, pcoll):\n",
        "        return (pcoll\n",
        "                | beam.Filter(lambda row: row['rssi'] >= self.value))\n",
        "    \n",
        "# Deja sólo los id client y luego selecciona los distintos ids.\n",
        "class Distinct(beam.PTransform):\n",
        "\n",
        "    def expand(self, pcoll):\n",
        "        return (pcoll\n",
        "                | beam.Map(lambda x: x.get('client'))\n",
        "                | beam.transforms.util.Distinct())\n",
        "    \n",
        "# Transforma cada fila del PCollection que recibe a la forma de\n",
        "# tupla (client, [lista de tiempos de cada visita])\n",
        "class Visits(beam.PTransform):\n",
        "    \n",
        "    # Recibe el umbral de visita\n",
        "    def __init__(self, rssiVisit):\n",
        "        self.rssiVisit = rssiVisit\n",
        "\n",
        "    # Función aplicada a cada fila del PCollection como map\n",
        "    # (en la función expand), que retorna la lista de tiempos\n",
        "    # de cada visita de client.\n",
        "    # Recibe una lista de tuplas de un client:\n",
        "    # [(rssi, date), (rssi, date), ...]\n",
        "    def getVisits(self, dataList):\n",
        "        \n",
        "        dataList = list(dataList)\n",
        "        # Se ordena la lista por date\n",
        "        dataList.sort(key=lambda rssi_date: rssi_date[1])\n",
        "    \n",
        "        # Lista de listas de visitas\n",
        "        visitsList = []\n",
        "        # Lista de tuplas\n",
        "        visit = []\n",
        "        # Se itera la lista de tuplas.\n",
        "        # Para una iteración se compara con date de la anterior,\n",
        "        # para eso se usa previousDate. Se inicia con el primer valor.\n",
        "        previousDate = dataList[0][1]\n",
        "        for rssi_date in dataList:\n",
        "            # Si la diferencia del tiempo anterior con el actual\n",
        "            # es menor de media hora. En la primera iteración es 0,\n",
        "            # por tanto ingresa al if.\n",
        "            if rssi_date[1]-previousDate < 1800000:\n",
        "                # Carga un registro de la visita como tupla (rssi, date)\n",
        "                visit.append(rssi_date)\n",
        "            # Si es mayor o igual, ese registro hace parte de la siguiente\n",
        "            # visita. En la lista de listas se agrega la visita anterior\n",
        "            # y se empieza una nueva con el primer registro.\n",
        "            else:\n",
        "                visitsList.append(visit)\n",
        "                visit = [rssi_date]\n",
        "            previousDate = rssi_date[1]\n",
        "        # Agrega la última visita.\n",
        "        visitsList.append(visit)\n",
        "        \n",
        "        # Hace falta que que haya mínimo una medición mayor al umbral de visita\n",
        "        # y que el tiempo entre esa medición y la última sea menor que 5 minutos,\n",
        "        # para que se considere una visita como tal.\n",
        "        \n",
        "        # Lista de los tiempos de visitas reales.\n",
        "        realVisits = []\n",
        "        # Se itera la lista de listas anterior\n",
        "        for visit in visitsList:\n",
        "            visitSize = len(visit)\n",
        "            # Se itera la lista de tuplas de registros correspondientes a una\n",
        "            # visita, hasta el penúltimo registro, y se confirma que pase\n",
        "            # el umbral de visita, ...\n",
        "            for i in range(visitSize-1):\n",
        "                if visit[i][0] >= self.rssiVisit:\n",
        "                    # ... de ser así toma el tiempo de diferencia entre dicha\n",
        "                    # medida y la última, ...\n",
        "                    visitTime = visit[visitSize-1][1] - visit[i][1]\n",
        "                    # ... si es mayor que 5 minutos, agrega el tiempo.\n",
        "                    if visitTime >= 300000:\n",
        "                        realVisits.append(visitTime)\n",
        "                    # Como ya encontró la medición requerida, quiebra el for.\n",
        "                    break\n",
        "\n",
        "        return realVisits\n",
        "\n",
        "    # Recibe PCollection anterior en el pipeline y aplica transformación las filas.\n",
        "    def expand(self, pcoll):\n",
        "        return (pcoll\n",
        "                | beam.MapTuple(lambda client, dataList: (client, self.getVisits(dataList))))\n",
        "    \n",
        "# Calcula el tiempo promedio de las visitas de cada client.\n",
        "class VisitorsTimeAvg(beam.PTransform):\n",
        "\n",
        "    # Calcula el promedio de una lista de enteros, y el valor lo convierte a minutos.\n",
        "    def mean(self, dataList):\n",
        "        total = 0\n",
        "        for data in dataList:\n",
        "            total += data\n",
        "        return int(total/(60000*len(dataList)))\n",
        "    \n",
        "    def expand(self, pcoll):\n",
        "        return (pcoll\n",
        "            | beam.MapTuple(lambda client, dataList: (client, self.mean(dataList))))\n",
        "\n",
        "# Recibe un PCollection con filas de la forma (client, número de visitas) y suma las visitas.\n",
        "class VisitsSum(beam.PTransform):\n",
        "\n",
        "    def expand(self, pcoll):\n",
        "        return (pcoll\n",
        "            | beam.Map(lambda row: row[1])\n",
        "            | beam.CombineGlobally(sum))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-Zhhj8dI6W4"
      },
      "source": [
        "# Creación de pipeline p con un DataflowRunner por defecto, y recibe las opciones\n",
        "# de configuración inicializadas al principio del notebook.\n",
        "p = beam.Pipeline(DataflowRunner(), options=options)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8aVGh6kI_3K"
      },
      "source": [
        "# ----- PIPELINE -----\n",
        "\n",
        "# Lee el archivo json y filtra para quedarse con las filas que tengan rssi mayor a 10 dBm.\n",
        "transeuntes = (p | 'lectura' >> ReadData('gs://jrodriguez-test/FuzzyData.txt')\n",
        "                 | 'filtroUmbralTranseuntes' >> FilterRssi(10))\n",
        "\n",
        "# Toma los id client distintos del PCollection transeuntes\n",
        "transeuntesMac = transeuntes | 'transeuntesDistintos' >> Distinct()\n",
        "\n",
        "# Cuenta el número de ids únicas de la salida anterior transeuntes.\n",
        "totalTranseuntes = transeuntesMac | 'conteoTranseuntes' >> beam.combiners.Count.Globally()\n",
        "\n",
        "# A partir de este punto ya registros de mediciones con umbral de transeúntes, ahora\n",
        "# queremos encontrar los visitantes.\n",
        "visitantesTiempoVisitas = (transeuntes\n",
        "    # Primer filtro (de dos) para poder pertenecer a una visita.\n",
        "    | 'filtroUmbralVisitantes' >> FilterRssi(15)\n",
        "    # Transforma las filas del PCollection recibido a tuplas de la forma ( client, (rssi, date) )\n",
        "    | 'seleccionVariables' >> beam.Map(lambda x: (x.get('client'),(x.get('rssi'), x.get('date'))))\n",
        "    # Agrupa por id client único y por cada uno obtiene una lista de tuplas. Cada fila queda de la\n",
        "    # forma ( client, [lista de tuplas (rssi, date)] )\n",
        "    | 'agruparMac' >> beam.transforms.core.GroupByKey()\n",
        "    # Calcula las visitas y convierte cada fila a la forma ( client, [lista de tiempos visitas])\n",
        "    | 'obtenerVisitas' >> Visits(20)\n",
        "    # Sólo continúan los que quedaron con elementos en la lista.\n",
        "    | 'filtroVisitantes' >> beam.Filter(lambda row : len(row[1]) > 0))\n",
        "\n",
        "# Recibe la PCollection visitantesTiempoVisitas y calcula el tiempo promedio. Cada fila queda\n",
        "# transformada de la forma: (client, tiempo_promedio_visita)\n",
        "visitantesTiempoProm = (visitantesTiempoVisitas\n",
        "    | 'promedio' >> VisitorsTimeAvg())\n",
        "\n",
        "# Recibe también la PCollection visitantesTiempoVisitas y hace el conteo de visitantes.\n",
        "totalVisitantes = (visitantesTiempoVisitas\n",
        "    | 'conteoVisitantes' >> beam.combiners.Count.Globally())\n",
        "\n",
        "# Recibe también la PCollection visitantesTiempoVisitas y calcula el número de visitas de cada\n",
        "# client, mediante la longitud de la lista de tiempos. Cada fila queda de la forma:\n",
        "# (client, número_visitas)\n",
        "visitasCliente = (visitantesTiempoVisitas\n",
        "    | 'conteoVisitas' >> beam.MapTuple(lambda client, dataList: (client, len(dataList))))\n",
        "\n",
        "# Suma todos los valores de la PCollection visitasCliente para obtener el total de visitas.\n",
        "totalVisitas = visitasCliente | 'sumaVisitas' >> VisitsSum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ds1MqvupJDnr"
      },
      "source": [
        "# Directorio para almacenar los archivos de salida del trabajo.\n",
        "output_gcs_location = '%s/output' % dataflow_gcs_location\n",
        "\n",
        "# Se incorporan las salidas del pipeline para escribir en Storage\n",
        "# en formato csv, mediante PTransforms de entrada/salida.\n",
        "\n",
        "(transeuntesMac\n",
        "    | 'Write transeuntes to GCS' >> beam.io.WriteToText(\n",
        "        # Nombre del archivo con toda la ruta.\n",
        "        output_gcs_location + '/transeuntes',\n",
        "        file_name_suffix='.csv'))\n",
        "\n",
        "(totalTranseuntes\n",
        "    | 'Write totalTranseuntes to GCS' >> beam.io.WriteToText(\n",
        "        output_gcs_location + '/totalTranseuntes',\n",
        "        file_name_suffix='.csv'))\n",
        "\n",
        "(visitantesTiempoVisitas\n",
        "    | 'Write visitantesTiempoVisita to GCS' >> beam.io.WriteToText(\n",
        "        output_gcs_location + '/visitantesTiempoVisitas',\n",
        "        file_name_suffix='.csv',\n",
        "        header='mac,tiempos'))\n",
        "    \n",
        "(visitantesTiempoProm\n",
        "    | beam.Map(lambda x: re.sub(\"\\(|\\)|\\'\", \"\", str(x)))\n",
        "    | 'Write visitantesTiempoProm to GCS' >> beam.io.WriteToText(\n",
        "        output_gcs_location + '/visitantesTiempoProm',\n",
        "        file_name_suffix='.csv',\n",
        "        header='mac,tiempoProm'))\n",
        "\n",
        "(totalVisitantes\n",
        "    | 'Write totalVisitantes to GCS' >> beam.io.WriteToText(\n",
        "        output_gcs_location + '/totalVisitantes',\n",
        "        file_name_suffix='.csv',\n",
        "        header='totalVisitantes'))\n",
        "\n",
        "(visitasCliente\n",
        "    | beam.Map(lambda x: re.sub(\"\\(|\\)|\\'\", \"\", str(x)))\n",
        "    | 'Write visitasCliente to GCS' >> beam.io.WriteToText(\n",
        "        output_gcs_location + '/visitasCliente',\n",
        "        file_name_suffix='.csv',\n",
        "        header='mac,visitas'))\n",
        "\n",
        "(totalVisitas\n",
        "    | 'Write totalVisitas to GCS' >> beam.io.WriteToText(\n",
        "        output_gcs_location + '/totalVisitas',\n",
        "        file_name_suffix='.csv',\n",
        "        header='totalVisitas'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcUFxdxCJHKi"
      },
      "source": [
        "# Corre pipeline y retorna el resultado.\n",
        "pipeline_result = p.run()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVXz2ERVJKfe"
      },
      "source": [
        "# El siguiente llamado espera hasta que el trabajo concluya. Toma unos minutos.\n",
        "pipeline_result.wait_until_finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC2GoD76JNS_"
      },
      "source": [
        "# Cuando el trabajo terminó podemos mirar muestras de los resultados, mediante el comando gsutil y head\n",
        "!gsutil ls {output_gcs_location}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAY2dWJ3JQ3t"
      },
      "source": [
        "!gsutil cat {output_gcs_location}/transeuntes* | head -10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpbSKv7FJTEl"
      },
      "source": [
        "!gsutil cat {output_gcs_location}/totalTranseuntes* | head -10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWdoRgs-JVYd"
      },
      "source": [
        "!gsutil cat {output_gcs_location}/totalVisitantes* | head -10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tNDlMqDJZdf"
      },
      "source": [
        "!gsutil cat {output_gcs_location}/visitantesTiempoProm* | head -10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK3w2k1kJZ-Q"
      },
      "source": [
        "!gsutil cat {output_gcs_location}/visitantesTiempoVisitas* | head -10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_Bhx1aqJcGF"
      },
      "source": [
        "!gsutil cat {output_gcs_location}/visitasCliente* | head -10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4Gj-jn7Jfh3"
      },
      "source": [
        "!gsutil cat {output_gcs_location}/totalVisitas* | head -10"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}